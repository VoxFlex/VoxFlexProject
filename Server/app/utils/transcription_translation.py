
import os
from dotenv import load_dotenv
import whisperx
import openai
from deep_translator import GoogleTranslator
import torch
import re
from num2words import num2words

load_dotenv(".env.local")
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY is not set in .env.local file")

client = openai.OpenAI(api_key=api_key)

def convert_numbers_to_words(text, lang="th"):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏≠‡πà‡∏≤‡∏ô"""
    def replace_number(match):
        number = match.group()
        return num2words(int(number), lang=lang)

    return re.sub(r'\b\d+\b', replace_number, text)
def refine_translation_with_gpt(text, segment_duration, previous_context=None, target_language="th"):
    """‡πÉ‡∏ä‡πâ GPT-4o ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏©‡∏≤"""
    text = convert_numbers_to_words(text, lang=target_language)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÉ‡∏ä‡πâ 2.5 - 3 ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
    max_words = int(segment_duration * 3)  # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 3 ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

    messages = [
        {"role": "system", "content": 
         f"You are a professional language editor. Your job is to shorten the text while keeping the meaning intact. "
         f"DO NOT translate. DO NOT change the language. DO NOT add or repeat sentences from previous context. "
         f"Ensure the text does not exceed {max_words} words."}
    ]

    if previous_context:
        recent_context = " ".join(previous_context[-2:])
        messages.append(
            {"role": "user", "content": f"Previous context:\n{recent_context}\n"
                                        f"Now, shorten the following text to fit within {max_words} words while keeping its meaning: {text}"}
        )
    else:
        messages.append(
            {"role": "user", "content": f"Shorten this text to fit within {max_words} words while keeping its meaning: {text}"}
        )

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    return response.choices[0].message.content

def transcribe_and_translate(audio_path, source_language="en", target_language="th", max_chunk_duration=7):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ WhisperX"""

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    compute_type = "float16" if torch.cuda.is_available() and torch.cuda.get_device_capability(0) >= (7, 0) else "float32"

    model = whisperx.load_model("small", device=device, compute_type=compute_type)

    # ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏° timestamps
    result = model.transcribe(audio_path, language=source_language, print_progress=True, verbose=True,chunk_size=max_chunk_duration)

    #  ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ transcription ‡πÑ‡∏î‡πâ `segments` ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if "segments" not in result or not result["segments"]:
        raise ValueError("Transcription failed: No segments found.")

    segments = result["segments"]

    # #  Alignment
    # align_model, align_metadata = whisperx.load_align_model(language_code=source_language, device=device)
    # aligned_result = whisperx.align(segments, align_model, align_metadata, audio_path, device)

    # #  ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö alignment output
    # if "segments" not in aligned_result or not aligned_result["segments"]:
    #     raise ValueError("Alignment failed: No aligned segments found.")

    # #  ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å `aligned_result["segments"]`
    # segments = aligned_result["segments"]

    translator = GoogleTranslator(source=source_language, target=target_language)
    previous_context = [] 

    for seg in segments:
        text_en = seg["text"].strip()
        segment_duration = seg["end"] - seg["start"]  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß segment ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

        # Translate to target language
        translated_text = translator.translate(text_en)

        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
        refined_text = refine_translation_with_gpt(translated_text, segment_duration, previous_context, target_language)
        refined_text = convert_numbers_to_words(refined_text, lang=target_language)
        
         # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï context
        previous_context.append(refined_text)
        if len(previous_context) > 2:
            previous_context.pop(0)

        seg["text"] = refined_text

    return segments



# üìå ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° GPT-4 (refine_translation_with_gpt()) ‚Üí ‡πÉ‡∏ä‡πâ AI ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô
# ‚úÖ ‡πÉ‡∏ä‡πâ WhisperX (whisperx.load_model()) ‚Üí ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö GPU acceleration
# ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GPU (torch.cuda.is_available()) ‚Üí ‡πÉ‡∏ä‡πâ float16 ‡∏ñ‡πâ‡∏≤ GPU ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
# ‚úÖ ‡πÉ‡∏ä‡πâ GoogleTranslator ‚Üí ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö max_chunk_duration ‚Üí ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ segment ‡πÉ‡∏´‡πâ ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô
# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° print_progress=True ‡πÅ‡∏•‡∏∞ verbose=True ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏ì‡∏∞‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î

# feat: Improve AI dubbing with GPT-4 translation & WhisperX optimization
# - Integrated GPT-4 (`refine_translation_with_gpt()`) to refine translations and make them more concise.
# - Optimized WhisperX for speech-to-text processing, including GPU acceleration (`float16` if supported).
# - Added `GoogleTranslator` to handle automatic language translation.
# - Set `max_chunk_duration=5` to limit segment length for better synchronization.
# - Enabled `print_progress=True` and `verbose=True` for better debugging.

# feat: Enhance AI dubbing with number conversion & GPT-4o refinement

# - Switched to GPT-4o for improved translation accuracy and contextual coherence.
# - Implemented `convert_numbers_to_words()` to replace numeric digits with Thai words for better readability.
# - Updated `refine_translation_with_gpt()` to maintain language consistency and prevent unwanted merging.
# - Introduced `previous_context` tracking to improve sentence flow without repetition.
# - Retained WhisperX speech-to-text optimization with GPU acceleration (`float16` if supported).
# - Ensured translated segments remain concise and correctly formatted.
# - Maintained debugging support with `print_progress=True` and `verbose=True`.

# üí° Summary:
# üîπ GPT-4o now respects natural speaking pace (max 3 words/sec).
# üîπ Translations are shorter and fit within each segment's duration.
# üîπ Numbers are automatically converted to words before processing.
# üîπ Better sentence consistency with improved context tracking.