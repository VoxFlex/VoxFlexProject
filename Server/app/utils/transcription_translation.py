
import os
from dotenv import load_dotenv
import whisperx
import openai
from deep_translator import GoogleTranslator
import torch

load_dotenv(".env.local")
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY is not set in .env.local file")

client = openai.OpenAI(api_key=api_key)

def refine_translation_with_gpt(text):
    """‡πÉ‡∏ä‡πâ GPT-4 ‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡πÅ‡∏õ‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡πà‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô"},
            {"role": "user", "content": f"‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÑ‡∏ß‡πâ: {text}"}
        ]
    )
    return response.choices[0].message.content

def transcribe_and_translate(audio_path, source_language="en", target_language="th", max_chunk_duration=5):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ WhisperX"""

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ GPU ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ GPU ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö float16 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    compute_type = "float16" if torch.cuda.is_available() and torch.cuda.get_device_capability(0) >= (7, 0) else "float32"

    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• WhisperX
    model = whisperx.load_model("small", device=device, compute_type=compute_type)

    # ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏° timestamps
    result = model.transcribe(audio_path, language=source_language, print_progress=True, verbose=True,chunk_size=max_chunk_duration)

    #  ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ transcription ‡πÑ‡∏î‡πâ `segments` ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if "segments" not in result or not result["segments"]:
        raise ValueError("Transcription failed: No segments found.")

    segments = result["segments"]

    # #  Alignment
    # align_model, align_metadata = whisperx.load_align_model(language_code=source_language, device=device)
    # aligned_result = whisperx.align(segments, align_model, align_metadata, audio_path, device)

    # #  ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö alignment output
    # if "segments" not in aligned_result or not aligned_result["segments"]:
    #     raise ValueError("Alignment failed: No aligned segments found.")

    # #  ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å `aligned_result["segments"]`
    # segments = aligned_result["segments"]

    translator = GoogleTranslator(source=source_language, target=target_language)

    for seg in segments:
        text_en = seg["text"].strip()

        # ‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        translated_text = translator.translate(text_en)

        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
        translated_text = refine_translation_with_gpt(translated_text)

        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏õ‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ô segments
        seg["text"] = translated_text

    return segments


# üìå ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° GPT-4 (refine_translation_with_gpt()) ‚Üí ‡πÉ‡∏ä‡πâ AI ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô
# ‚úÖ ‡πÉ‡∏ä‡πâ WhisperX (whisperx.load_model()) ‚Üí ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö GPU acceleration
# ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GPU (torch.cuda.is_available()) ‚Üí ‡πÉ‡∏ä‡πâ float16 ‡∏ñ‡πâ‡∏≤ GPU ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
# ‚úÖ ‡πÉ‡∏ä‡πâ GoogleTranslator ‚Üí ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö max_chunk_duration ‚Üí ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ segment ‡πÉ‡∏´‡πâ ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô
# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° print_progress=True ‡πÅ‡∏•‡∏∞ verbose=True ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏ì‡∏∞‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î

# feat: Improve AI dubbing with GPT-4 translation & WhisperX optimization
# - Integrated GPT-4 (`refine_translation_with_gpt()`) to refine translations and make them more concise.
# - Optimized WhisperX for speech-to-text processing, including GPU acceleration (`float16` if supported).
# - Added `GoogleTranslator` to handle automatic language translation.
# - Set `max_chunk_duration=5` to limit segment length for better synchronization.
# - Enabled `print_progress=True` and `verbose=True` for better debugging.